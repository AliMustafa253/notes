What's AWS?

	On demand services.
	
	
================

can skip 3,4,5 and 12

networks = availability zones
	
--AWS Regions--
	region = cluster of data centers
	region scoped = services acc to region
	
	-where to choose aws region?
	
		- compliance with data gov and legal
		- proximity
		- Available services
		- pricing: varies per region
		
--AWS availability zone--
	usually 3 min 3 max 6.
		ap-southeast-2
		eg ap-southeast-2a,b,c
		
		- 1 or more data centers with redundant power and networking.
		- isolated from each other for disaster prevention
		- connected with high bandwidth and low latency networking -> form region
	
--Edge Locations--
	400+ point of presences.
	Content delivered to end users with low latency.
	
-some services like route 53 = global
others regional like ec2 --> aws regional services check availability per region


--IAM--
	Root account = default, should be used to create accounts/users.
	
	users = can be in multiple groups
	groups = only contain users.
	
	-- Policies--  
		= json documents assigned to them (things allowed to them)
		
		"version"
		"id" optional
		"Statement"{
			"sid"
			"Effect" : "Allow" / "deny"
			"Principal : { } --> which account/user/role it is applied to
			"action" list of actions this policy allows or denies
			"resources": list of resources which the action applies to
			"condition" conditions for policy to take effect
		
	
	***Least privilege principle.
	
	Password Policy:
		password expiry,reuse,allow iam to change own passwords,specific char tyesp
		
		MFA-Multifactor Authentication

			Management Console  ---> password + MFA-Multifactor
			AWS CLI  -> access keys
			AWS SDK -> access keys
			
	---CLI---
		access keys
		
		aws configure
		aws iam list-users
	
	---CloudShell---
		Cli on the cloud
		Saves files as well.
		download and upload files.
			in some regions only
			
	--IAM roles for Services--
		IAM roles
		--> like users but used by aws services
			EC2 instance = IAM Role ---> one entity.
				Common roles:
					EC2 Instance Roles.
					Lambda Function Roles.
					CloudFormation Roles.		
		AWS service role
	
	--IAM Security Tools--
		IAM Credentials Report (Account-level)
		IAM Access Advisor (User-level)
			See which access not used
				---> to do least priviledge
				
	***IAM groups contain only users (not other groups)
	**A statement in an IAM Policy consists of Sid, Effect, Principal, Action,
	Resource, and Condition. Version is part of the IAM Policy itself, not the statement.
			
		
===EC2====
	
	Elastic Compute Cloud = Infrastructure as a service.
	
	usecases:
		- Rent Virtual Machines. (EC2)
		- Storing data on virtual drives (EBS) 
		- Distributing load accross machines (ELB)
		- Scaling the services using an auto-scaling group (ASG)
	
	--EC2 sizing & configuration--
		- OS
		- CPU
		- RAM
		- Storage Space 
			- Network attached (EBS/EFS)
			- hardware (EC2 instance store)
		
		- Network card: speed , public ip address
		- Firewall rules: security group
		- Bootstrap script (config at start): EC2 User Data
		
	--EC2 User Data--
		bootrstrap instances using EC2 userdata script.
		bootstrapping = launching commands when a machine starts.
			script runs only once at instance first start
			EC2 user data is used to automate boot tasks such as:
				- installing updates.
				- installing softwares.
				- downloading common files.
				- anything u can think of.
		**EC2 User Data Script runs with root user
	
	t2.micro --> free tier 1 cpu 1gb memory. can run for a month t3 if not in region
	t2.2x --> not free
	...etc
	
	key pair .pem for all but .ppk for windows 8 and 7
	
	Delete on termination = EBS volume deleted
	
	Using user data run script ->
		eg install http web server. Write file that will be our server. echo
		
	AMI -> amazon machine image -> linux for us
	
	=======EC2 INSTANCE TYPES=========
	DIFF BETWEEN STORAGE OPTIMZED AND MEMORY OPTIMIZED?
	
	e.g m5.2xlarge
	m: instance class -> general
	5: generation (AWS improvers them over time)
	2xlarge: size within instance class
	
	General Purpose: M
		Good for diversity of workloads such as web servers or code repos.
		Balance b/w:
			compute
			memory
			networking
	
	Compute Optimized: C
		Good for compute intensive tasks:
			Batch processing workloads
			Media transcoding
			High performance web servers
			High performance computing (HPC)
			Scientific modeling and Machine Learning
			Dedicated Gaming Servers
			
	Memory Optimized: R -> for RAM
		Fast process large data sets in memory
			High performance, relational/non rel db
			distributed web scale cache
			in memory db optimized for Businees intelligence
			Applications performing real time processsing of big unstructued data.
			
	
	Accelerated Computing:
	
	Storage Optimized: I G or H1
		Great for storage related data on local storage.
			High frequency online transaction processing.
			Rel or NOSQL DB
			Cache for in memory db (redis)
			Data warehousing applications
			Distributed file systems
	
	=========EC2 INSTANCES PURCHASE OPTIONS===============
	
	On-demand Instances- 
		short workload predictable pricing , pay by sec
			- Highest cost but no upfront payment.
			- no long term commitment.
			SHORT TERM AND UN INTERRUPTED WORKLOADS, cant predict app behaviour
		
	Reserved (1 & 3 years)
		Reserved Instances. long workloads
		Convertible Reserved Instances. Long workloads with flexible instances
			- Up to 72% discount on on demand.
			- Reserve specific instance attributes (instance type region, tenancy OS)
			- Reservation period 1 year / 3 year (+++ discount)
			- Payment Options- No Upfront (+), Partial ++, All Upfront (+++)
			- Reserved Instances Scope - Regional or Zonal (reserve capacity in AZ)
			- Recommended for steady state usage app (db)
			- Buy and sell in Reserved Instance Marketplace
			
			COnvertible Reserved Instance.
				Can change EC2 Instance type, family,OS,Scope,Tenancy
				Up to 66% Discount
			
	Savings Plan (1 & 3 years) 
		commitment to an amount of usage long workload.
			- 72% -> Same as Reserved
			- Commit to certain type of usage (10$/hour for 1 or 3 years)
		***	- Usage beyond EC2 Savings Plans is billed at On-Demand Price
			
		***	- Locked to specific family and AWS Region ( e.g M5 in us-east-1)
			- Flexible Across :
				- Instance size (e.g, m5.xlarge,m5.2xlarge)
				- OS
				- Tenancy (Host,Dedicated,Default)
				
	Spot Instances - 
		short workloads, cheap, can lose instances ( less reliable )
			- Up to 90% discount.
			- Max price set as spot price.
			- MOST cost efficient.
			
			*** USEFUL FOR:
				Batch Jobs
				Data Analysis
				Image Processing
				Any Distributed Workloads
				Workloads with a flexible start and end time
			
			- NOT FOR CRITICAL JOBS LIKE DB
	
	Dedicated Hosts- 
		book an entire physical server, control instance placement.
			- Physical Server with EC2 Instance capacity fully dedicated
			- ALlows you address compliance requiremetns and use ur existing server bound licenes
			(per socket, per core, per--VM software licenes)
			
			- Purchasing options.
				On demand- pay per second
				Reserved 1 or 3 years. (No Upfront/Parital, All Upfront etc)
			- MOST expensive.
			- Useful for licensing model.
			Or compliance needs.
	
	Dedicated Instances - 
		no other customers share ur hardware. Cna share with same acc.
		-*** No control over instance placement (can move after stop/start)
		
			- MY OWN INSTANCE IN MY OWN HARDWARE.
			- Dedicated host -> allow control over lower level hardware and access to physical server
	
	Capacity Reservations - 
		reserver capacity in specific AZ for any duration
			- Always have Access to EC2 capacity when needed 
			- No time commitment. NO BILLING DISCOUNT ITSELF
			- Combine with Regional Reserved Instances and Savings plan for discounts.
			- Charged on demand rate whether you run instances  or not.
			
			Suitable for short-term uninterrupted workloads that need to be in a specific AZ
		
	-----------Spot instance requests--------------
		
		Define max spot price. get instance while current spot price < max
			2min grace period when price > max. 
				- stop or terminate 
				- Spot Block:- Block spot instance until specific time (1 to 6 hours)
					Rare situations can be reclaimed. without interruption
			
			good for resilient ML etc short work not for DB
			discount upto 90%
			
		---One time request for spot-
			as soon as spot request fulfilled -> launch instances and request finished
			max price instances, launch specs, 
		persistent
			as long as there.
			
		*** CANCEL -> open active or disabled state
		***Cancelling spot req does not terminate instances.
		cancel spot req first then terminate instance.
		
		----------Spot fleets---------
			Set of spot instances + (optional) On demand Instances
			Spot fleet try to meet target capacity with price constraints.
				- Define possible launch pools: instance type,OS,AZ
				- can have multiple launch pools.
				- Spot fleet stops launching instances when reach capacity.
				
			Strategies to allocate Spot Instances:
			****- LowestPrice: pool with lowest Price (cost optimzation, short workload)
				- Diversitifed: distributed across all pools (great for availablility, long workloads)
				- CapacityOptimized: optimal capacity for number of instances avaialble
				- priceCapacityOptimized(recommended) pools with highest cap available ,t hen select the pool with 
					lowest price (best choice for most_/
			
			--Spot fleets allow us to automatically resserve spots with lowest price.
		
			
	
	=======SECURITY GROUPS=======
		only contain allow rules.
		rules can reference by IP or by security groups.
		
		inbound traffic ---> sec group
		outbound traffic <----
		
		firewall on EC2 Instances.
			access to ports.
			authorised ip ranges - ipv4 and 6
			control inbound and outbound network.
			
		*good to maintain one speerate for ssh access
		------------------------------------
		*can have multiple instances.
		****locked down to region/VPC combination
		*live outside EC3 - if traffic blocked EC2 wont see.

		*********if timeout/not accessbile = security group error.**********
		if connection refused error -> application error or not launched
		
		inbound traffic is blocked by default.
		outbound is authorised by default.
		
		authorised specific security groups as well. multiple sec groups allowed.
		
		
		=======PORTS========
		
		22 = SSH (secure shell) - log into linux instance
		21 = FTP - upload files into a file share
		22 = SFTP upload file using SSH
		80 = HTTP - access unsecured sites
		443 = HTTPS - access secured websites
		3389 = RDP (remote desktop protocol) log into a windows instance (FOR WINDOWS)
		
		======SSH======
		secureshell protocol
			commandline interface utility --> usable in mac linux and windows 10 
			> others putty.
			> EC2 instance connect = all
		
		allows u to use ec2 ssh/control from ur machine remotely
		ec2-user = user setup itself in linux ec2 instance
		
		when using ssh. make sure ur key-pair is connected to ur account only.
		
		EC2 Instance Connect
			- temporary ssh key given.
			sometimes need to add both ipv4 and v6 in security to connect
			
		--> NEVER ENTER IAM KEY IN SSH INSTANCE ETC
		
	==================================
		private (unqiue only accross private network) 	public IP ( unique)
			private internet gateway (NAT device)
		Elastic IPs
			EC2 instance changes public IP.
			Elastic IP = fixed public IP and u own it. one instance at a time
			You can mask failure by remapping address.
			Only 5 in Elastic IP per account.
			
			---> Better = random public IP and register a DNS name
			Elastic I{ = usually poor architectural decisions.
			
		EC2 ---> private IP for internal AWS network only
		
	---------EC2 Placement Groups--------
	
		control over ec2 instance placement.
		strategy can be defined without hardware access.
			Cluster: clustere instances into low latency groupp in a single AZ
					---> great network (10gbps badnwitdh between instances)
					
					<--- if AZ fails, all instances fails at the same time.
					
					Use Case:
						Big Data Job that needs to complete fast.
						Apps that need extremely low latency and high network throughput
			
			
			Spread: spread instances across underlying hardware (max 7 instance per group per AZ)
					- for critical applications.
					
						Minimise failure risk.
						Different hardwares.
					
					---> can span across diff AZ, EC2 in diff physical hardware.
						Reduce risk in simultaneous failure
						
					<--- limited to 7 instances per AZ per placement group
					
					Use Case:
						Applications that needs to maximize high availability
						Critical Applications where each instance must be isolated from failure from each other
					
			Partition: spreads instances across many diff partitions. ( rely on diff sets of racks)
					within an AZ. Scales to 100s of EC2 instances per group (hadoop, Cassandra, Kafka)
					
				diff parititons. each partition represents diff rack.
				Up to 7 partitions per AZ. 
				Can span across multiple AZ in same region.
				Up to 100s of EC2 Instances.
				Dont share hardware rack in each partition --> each partition isolated from failure.
				EC2 metadata to see where each service is.
				Use cases -> big data apps
				
		------- Elastic Network interfaces (ENI) ------------
		logical component in a VPC representing a virtual network card
		ENI can have:
			- primary private IPv4, and multiple secondary ipv4
			- Elastic IPv4 per private IPv4
			- One or mroe security groups
			- A MAC Address
		Make ENI indepedentally and attach them to EC2 instances on failover.
		Specific to AZ
			---> can move private IPv4 to diff EC2 FOR *** FAIL OVER PURPOSES
			
		secondary ENI ---> can move from one to another. can make ez network failover
		
		---------EC2 Hibernate----------
		
			stop,terminate instances:
				STOP -> EBS INTACT
				TERMINATE -> EBS Vol set up to be destroyed is destroyed.
				
			on start,
				OS boots ec2 user data.
				App starts , cache warms up time taken
				
		Hibernate
			in-memory RAM state preserved
			instance boot much faster (OS not stopped)
			RAM is written to a file in the root EBS vol.
			Root EBS vol is encrypted
				root EBS contains RAM dump.
				as if EC2 never stopped
				
			Use cases:
				long running processing.
				Save RAM state
				Faster OS boot
		AMI- a lot instance size -> not for bare metal instances.
		***Root Volume ---> must be EBS encrypted not instance store and large
		
	To enable EC2 Hibernate, the EC2 Instance Root Volume type must be an EBS volume
	and must be encrypted to ensure the protection of sensitive content.
	
===============EC2 STORAGE===============
	-------EBS---------		Elastic Block Store
		- EBS volume is a network drive u attach to ur instances.
		- Allows instance to persist data even after termination.
		- only mounted to one instance at a time (except io1/io2)
			2 EBS can be linked to one EC2
		- bound to a specific AZ
	*NETWORK USB STICK analogy
	
	EBS Volume:
		network drive not physical drive.
			uses network to communicate --> might have latency.
			detachable from one ec2 to another.
			
		Locked in AZ.
			Move volume across --> snapshot it.
			
		have a provisioned capacity
			- billed for provisioned capacity.
			- can increase capacity over time.
			
	
	----Delete on Termination Attribute-----
		Default true on root ebs volume.
		by default any other attached ebs is not deleted (disabled)
		Use case: preserve root vol when instance is terminated etc
	
	-----EBS SNAPSHOT-----
		Backup of ur ebs volume at a point in time
		Not necessary to detach volume but recommended.
		** CAN COPY SNAPSHOT ACROSS AZ OR REGION
	
		- EBS snapshot archive.
			archive tier --> upto 75% cheaper.
			- 24 to 72 hours to restore archive.
		
		- Recycle Bin for EBS Snapshots.
			setup rules to retain deleted snapshots.
			- retenship from 1 day to 1 year.
			AZ specific retention rules inside bin
			
		- Fast Snapshot Restore (FSR)
			Force full initialization of snapstho to have no latency on first use.
		
		
	------AMI------
	
	Amazon Machine IMage.
		Customization of an EC2 instance.
			- add ur own software configuration, os, monitoring
			- faster boot/ configuration time bcus all ur softaware is pre packaged.
			
		- AMI are built for a specific region ( can be copied to other region)
			- Public AMI
			- Own AMI : maintain urself
			- AWS Marketplace AMI
		
		Start an EC2 instance and customize it.
		Stop instance for data integrity.
		Build an AMI - also creates EBS snapshots
		Launch instance from other AMIs
		
	----Ec2 Instance Store------
	****EBS limited performance as network drives.
	
	--> high performance hardware = use EC2 Instance Store.
		- Better I/O performance
		- EC2 Instance Store Lose their storage if they're stopped 
		- Good for buffer / cache / scratch data/ temp content
		- Risk of Loss if hardware fails
		- Backups and Replication ur responsibility
		
	--------EBS VOLUME TYPES--
	
		Gp2/gp3 (SSD): general purpose SSD vol that balances price and performance.
			:**** cost effective storage,low latency.
			Sys boot vol, virtual desktop, dev and tes
			1 GB - 16 Tib
				gp3:
				-> independentally set IOP and throughput while gp2 is linked together
				
					baseline of 3,000 IOPS throughput of 125MB/s
					can increase up to 16,000 and 1000 MiB/s independetly
				gp2:
					small gp2 can burt iops to 3,000
					size IOPS and vol linked.
					3 IOPS per GB. max IOPs 16,000
		
		Iol/io2 Block Express (SDD): highest performance mission critical low =-latency or high throuput workloads.
			Critical Business applications with sustained IOPS performance.
			Or application needs more than 16,000 IOPS
			Great for db workloads (sensitive to storage perf and consistency)
			
				io1 (4GB-16Tb):
					can increase PIOPS independetly from storage size
				
				io2 (4Gb-64Tb):
					sub milisecond latency
					IOPS:GB ratio of 1000:1 for max piops
					
				Supports EBS: multi attach
		
		st1 (HDD): low cost HDD vol for freq-access throughput intensive workloads.
		sc1 (HDD): lowest cost HDD vol for less freq access 
			cannot be boot volume
			125gb to 16tb
		****Throughput Optimized HDD
				Good for big data data warhouses, log processing.
				Max throughput 500Mbs IOPS 500 in st1 half in sc1
			Cold HDD (sc1:)
				for data infreq access.
				low cost imp
		
		EBS Vol characterized in SIZE | THROUGHPUT | IOPS (I/O per sec)
		Only gp2/gp3 and io1/io2 can be used as boot vol


		--EBS multi attach--
			same EBS volume to multiple EC2
			only for io1 and io2
			- read and write permissions to both.
			Use case:
				Higher app availability in clustered linux application.
				Applications must manage concurrent write operations
				one AZ obv.
			***Up to 16 EC2 instances at a time.
			cluster aware file system
			
		--EBS encryption--
		
		Data at rest encrypted.
		ALl data in flight moving b/w instance and vol is encrypted.
		All snapshots encrypted
		all vol created from snapshot encrypted.
		**Encrypt decrypt handled transparently (we do nothing)
		EBS leverages keys from KMS (AES-256)
		**Copying unecrypted snapshot allows encryption
			or create EBS volume and select encryption to make new encrypted EBS vol
		
		create ebs snapshot of vol (non encrypted ebs)
		encrypt ebs snapshot (using copy)
		create new ebs vol from snapshot 
		attached encrypted vol to original instance
		
		
	=========EFS==========
	Elastic FIle System
	
	- Managed Network File System (NFS) can be mounted on many ec2
	- multi-AZ
	- Highly available scalable, expensive (3x gp2), pay per use
	
	Use cases: content management, web serving, data sharing
	NFSv4.1 protocol.
	security group to control access to EFS
	COmpatible with linux based AMI (not WINDOWS)
	Encrypted using KMS
	standard api posix linux
	File system scales automatically pay per use
	
	EFS Scale:
		- 1000s of nfs clients, 10gbps throughput
		- Grow to petabyte scale nfs, auto
	
	Performance Mode (set at EFS creation Time)
		- General Purpose: latency use cases (webserver, CMS etc)
		- Max I/O - higher latency, throughput, highly parallel (big data, media processing)
		
	Throuhput Mode
		- bursting - 1 TB = 50mbps + burt up to 100mbps.
			Scale with storage being used
		- Provisioned - set throughput regardless of storage size, 1 gbps for 1tb storage 
			deco related to storage.
		- Elastic - automatically scales throughput up or down  based on workloads.
			Great for unpredictable workloads
			
	Storage Tiers: 		lifecycle management feature - move file after N days
	
		- Standard : for frequently accessed files.
		
		- infrequent access (EFS-IA) cost to retrieve files, lower price to store.
		
		- Archive: rarely accessed data: 50& cheaper.
		
		implement lifecycle policies to move file b/w storage tiers.
		
	Availability and durability:
		Standard: Multi AZ
		One Zone: One AZ, great for dev
	
	can save up to 90%
	
	EFS attaches Security groups itself to EC2 once connected to allow connection
	
	
	============EBS v.s EFS=============
	EBS volumes:
		One instance except io1/io2 edgecase
		are locked to AZ level
		gp2: IO increases if disk size increases.
		gp3/io1: increase IO independently
		
	Migrate ---> snapshot----> restore snapshot to another AZ.
	EBS backups use IO and not run during app runing a lot traffic.
	Root EBS vol gets terminated by defualt but can be disabled.
	
	EFS:
		Mounting 100s of instances across AZ.
		EFS share website files.
		Only for linux.
		
		EFS has a higher price point for EBS.
		Level storage tiers for cost savings.
		
		************EFS v.s EBS v.s instance store**********
		
	
	========Scalability and high availability===============
	Vertical scalability:
		common for non distributed systems like db
		RDS, elasticache 
		limited
		
	Horizontal scalability:
		Distributed system. common for web app modren apps.
		Auto Scaling Group or load balancer
		
	t2.nano 0.5g ram 1vcpu,
	u-12tb1.metal - 12.3tb ram 448 vcpu
	
	=======ELB=======
	
		load balances servers that forward traffic to multiple servers downstream.
	
			Spread load across multiple downstream instances.
			expose a single point of access (DNS)
			Seamless handling of failures.
			Regular health checks
			provide SSL to websites.
			Enforce stickiness with cookies.
			High availability across zones
			Seperate public traffic from private traffic
			
	ELB
		Managed load balancer.
			AWS handles it and upgrates and also configuration knobs and tweaking.
			
		No brainer to use as costs less than using own load balancer.
		Integrated with many AWS offerings.
			EC2, EC2 Auto Scaling
			ACM, CloudWatch
			Route 53,AWS WAF etc.
			
	---Health Checks---
		Ensure EC2 working properly
		Crucial for ELB.
		Done by port and route to check
			e.g /health port 4567 protocol HTTP
			if not 200 then unhealthy wont send traffic.
			
	-----Classic Load Balancer -(old gen v1 2009) CLB-----
		HTTP,HTTPS,TCP,SSL	Deperecated
		
	-----Application Load Balancer (v2) 2016 - ALB----
		HTTP,HTTPS,WebSocket
			
		Layer 7 (HTTP)
		Load balancer to multiple HTTP applications across machines (target groups)
		Load balancer to multiple applications on same machine.
		Support redirects (from HTTP to HTTPS eg)
		
		Routing based on path in url (example.com/users & example.com/posts)
				based on hostname in url (one.example.com)
				based on Query String,Headers. (as,example.com/users?id=123&order=false_
		
		****ALB are a great fit for micro services and container based apps (docker and amazon ecs)
		**Has a port mapping feature to redirect to a dynamic port in ECS
		in comparison we'd need multiple classic LB per app
		
		--Target Groups--
		
			- EC2 instances - HTTP
			- ECS task - HTTP
			- Lambda Functions - HTTP Request translated to JSON
			- IP Addresses - must be private IPs
			
			ALB can route to multiple target groups. Health checks are at target group lvl

		Get fixed hostname
		App servers dont see ip of client.
			****true IP inserted in the header X-Forwarded-For.
			We can slo get Port and proto from X-forwarded
			
		*****RULES
		-----REDIRECT on specific header http etc
		Priority 
		
		
	----Network Load Balancer (v2) 2007 -NLB----
		TCP,TLS,UDP,Secure (TCP), (UDP)
			Millions of req per seconds.
			less latency 100ms v.s 400ms ALB
		NLB has one FIXED IP for each AZ  and supports assigning Elastic IP (helpful for whitelisting specific IP)

		
		NLB for extreme performance, TCP or UDP traffic
		
		---TARGET Groups---
			EC2 Instances.
			IP Addresses - must be private IPs
			ALB ---> FIXED IP and ALB = RULES FOR HTTP.
			Health Checks support TCP,HTTP and HTTPS protocols
		
	----Gateway Load Balancer GWLB 2020----
		Operates at layer 3 (network layer) IP protocol.
		
	- Some lb can be internal (Private) or external (Public)
	- Deploy,scale and manage fleet of 3rd party network virtual appliances in AWS
	
	- ****Firewalls, intrusion Detection and prevention systems, Deep Packet Inspection systems,
		payload manipulation.
	
	- Combines the following functions:
		Transparent Network Gateway: single entry/exit for all traffic.
		Load Balancer - distribute traffic to ur Virtual Appliances.
	**Uses the GENEVE protocol on port 6081
	
	
	---TARGET GROUPS---
		EC2 INSTANCES
		IP Addresses - must be private IPs
		
	---Security groups ELB---
	
	User Access anywhere from HTTPS
	EC2 HTTP restricted to Load Balancer.
		EC2 Allow traffic only if coming from load balancer
		
	--Sticky Sessions--	
		same client always redirected to the same instance behind a load balancer.
		
		- CLB ALB and NLB
		- Cookie used for stickiness - can expire.
		- same backend for session data.
		- Can bring imbalance to load.
		
		Application- based cookies:
			Custom cookie:
				Generated by target. Cookie name specified indibudally for each targ group.
				Custom attributes can be included by app.
				Dont use AWSALB,AWSALBAPP or AWS ALBTG reserved by ELB.
			Application Cookie:
				Generated by load balancer
				Cookie name is AWSALBAPP
		
		Duration-based Cookies:
			Cookie generated by load balancer.
			Cookie name is AWSALB for AWS ALB and AWSELB for CLB
		1 sec to 7 days
		
	---Cross-Zone Load Balancing---
		each load balancer instance distributes evenly across 
		all registered instances in all AZ.
		
		e.g 10% traffic to all instances 
		
		Without = traffic in less instance AZ = more % (50 50 in each but 25 25 in 2 and 10 10 in 5)
		
		ALB on default
			no charges for inter AZ data.
			target group = remove otherwise always on 
			***Cant route based on geography
			
		NLB disabled by default.
			charges for inter AZ data.
			Network Load Balancer has one static IP address per AZ and you can attach an Elastic IP address to it. 
			Application Load Balancers and Classic Load Balancers have a static DNS name.
			
			**the NLB supports HTTP health checks as well as TCP and HTTPS
			
		CLB
			Disabled by default.
			no charge
		
	
	======SSL======
		allows traffic b/w ur clietns and load balance to be encrypted in transit
		
		SSL --> Secure Socket Layer. used to encrypt connections.
		
		TSL -> Transport Layer Security --> newer version.
		
		TLS cert mostly used.
		
		SSL certificates issued by Certificate Authoritites (CA) Comodo,GoDaddy,Symantic,GlobalSIgn etc.
		
		SSL cert --> epiration date u set. must be renewed.
		
		Load Balancer --> instance = HTTP OVER VPCS
		
		Load balancer uses an X.509 cert (SSL/TSL)
		Manage certs using ACM (AWS CERTIFICATE MANAGER)
		Create/upload ur own cert alt
		
		HTTPS listener:
			must specify default cert
			optional list of certs to support mult domains.
			clients can use SNI to specify hostname they reach.
			Ability to specify a security policy to support legacy clients.
			
		---SNI---
			How to load multiple SSL certs into one web server (to serve multiple websites)
			newer protocol. requires cleint to indicate hostname of target server.
			In initial SSL handshake.
			
			Server will find correct cert or default
			
			Only for ALB and NLB, CloudFront.
			
		
			CLB:
				only one SSL cert.
				
		---Connection Draining---
			AKA Deregristration Delay - FOR ALB AND NLB.
			
				time to complete in-flight requests while instance is de registering or unhealthy.
				**Stops sending new request to ec2 instance which is de registering.
				
				b/w 1 to 3600 seconds (default 300sec)
				0 = disabled.
				set to low if req short
		
	=======ASG=====	Auto Scaling Group.
	
	Scale out (add ec2 instances)
	Scale in (remove EC2)
	ensure min and max number of EC2 instances.
	Automatically register new instances to a load balancer.
	Re create an EC2 instance in case prev one terminated.
	
	ASG is free (pay for instances)
	
	Health check can go to ASG and can terminate if unhealthy ec2 instance.
	
	---> Good combination with ELB
	
	Launch Template:
		AMI + Instance Type.
		EC2 User Data EBS Vol SEc Group SSH KEY PAIR IAM ROLES NETWORK LOAD BALANCER INFO
		Scaling Policies
		Min Max
		
	CloudWatch Alarms can trigger a metric used to scale in or out
	
		---Scaling Policies---
		
		Dynamic Scaling:
			Target tracking scaling:
				Simple set up.  eg ASG CPU to stay at around 40%
			Simple  / Step Scaling:
				CloudWatch Alarm triggered then add 2 units or remove 1 etc
			
		Scheduled Scaling:
			Anticipate a scaling based on known usage patterns.
			Increase min cap to 10 at 5pm on fri
		
		Predictive Scaling:
			Continously forecast load and scheduling scaling ahead.
			
	Good metrics to scale on:
		CPU Utilization:
		RequestCountPerTarget: Make sure stable
		Average Network In/ Out: (if app network bound)
		Any custom Metric( using cloudwatch)
		
	ASG - Scaling Cooldowns.
		After scaling activity happens, ur in a cooldown period (default 300sec)
		If in cooldown period, ASG will not launch or terminate instances.
		
		Advice: use a ready to use AMI to reduce config time in order to server req faster and reduce cd
		Faster active = less cd
		
		
==========RDS=============
		Relational Database Service
		Managed DB service uses SQL
		allows you to create db in cloud managed by AWS:
			Postgres, MySql,MariaDb,Oracle,SQL Server,Aurora,IBM smthn
			
		--Advantage over using RDS versus deploying DB on EC2--
			- RDS is a managed service:
				Automated provisioning, OS patching.
				continous backups and restore specific timestamp.
				Monitoring dashboards.
				Read replicas for improved read performance.
				Multi AZ setup for DR (Disaster Recovery)
				Maintenance windows for upgrades
				Scaling (vert and horizontal)
				Sotrage backed by EBS (gp2 or io1)
		Cant SSH into your RDS instance
		
		-----RDS - Storage Auto Scaling----
			Helps you increase storage on RDS DB instance dynamically.
			RDS detects you re running out of free db sotrage, scales auto.		
			Maximum Storage Threshold (max limit)
			Auto storage if:
				less than 10% of allocated free.
				Low-storage lasts at least 5min
				6 hours passed since last mod
				
		--RDS Read Replicas for read scalability--
		
			Helps scale reads
			Up to 15 Read Replicas
			Within AZ , Cross AZ or Cross Region.
			***Replication is ASYNC so reads are eventually consistent.
			Replicas can be promoted to their own DB.
			App must update connection string to leverage read replicas.
			
			***Use Case***
			
			- Production db is taking on normal load.
			- You want to run a reporting app to run some analytics.
			- Create a read replica to run new workload there.
			- Production app unaffected
			Read replicas are used for SELECT (=read) Only kind of statements
			(not DELETE,UPDATE,INSERT)
			
			- Network Cost:
				Normally cost when data goes from one AZ to another.
				For RDS Read Replicas within same reigon, you dont pay that fees.
				
			RDS Multi AZ (disaster Recovery)
				Sync replication.
				Replicate every change synchronously.
				One DNS name - auto app failover to standby
				Increase availability.
				Failover in case of loss of AZ, loss of network, isntance or storage failure.
				No Manual intervention in apps (new RDS is made master if failover)
				Not used for scaling.
				
				****Read replicas be setup as Mutli AZ for Disaster Recovery***
				
			From Single-Az to Multi-AZ
				Zero downtime Operation
				Just click on modify for db.
				Snapshot taken. New DB is restored from the snapshot in a new AZ and Sync established.
			
			
	---RDS CUSTOM---
		RDS we cant access underlying db customization
		
		RDS Custom we have OS and db customization: IN ONLY ORACLE AND MICROSOFT SQL.
		
			RDS: automates, setup, operation and scaling of db in aws.
			Custom: acces the underlying db and OS so you can.
				Configure settings
				install patches
				enable native features.
				access underlying ec2 instance
			Deactivate automation mode to perform customization better to take snapshot b4.
			
		RDS v.s RDS Custom:
			RDS: entire db and OS managed by AWS. 
			Custom: we have full admin access.
		
=====AURORA======
	
	- Aurora is not open sourced ( propreitary tech )
	
	- Postgres and MySQL supported in Aurora DB.
	
	- AWS cloud optimized and claims 5x perforamce over MySql on RDS, over 3x of Postgres
	
	- Aurora storage auto grows in increments of 10GB up to 128TB.
	
	- Aurora can have up to 15 replicas and faster than MySQL replication.
	
	- Failover is Instantaneous.
	
	- Costs more than RDS (20% more) - but more efficient.
	
	----High availability and read scaling-----
	
	6 copies of your data across 3 AZ:
		4 copies out of 6 needed for writes.
		
		3 copies out of 6 need for reads
		
		Self healing with peer to peer replication
		
		Storage is striped across 100s of vol
	
	- One Aurora Instance takes writes (master)
	- Failover in 30 sec.
	- Master + up to 15 read replicas that can turn into masters in failover.
		Support Cross Region Replication via Read Replicas
		
	** Writer Endpoint -> pointing to the master. Redirect to write instance always.
	** Auto Scaling in the Read Replicas
	
	***** READER ENDPOINT - help connection load balancing - connects automatically to read replicas
		
	Auto fail over, backup and recovery, isolation adn security, push button scaling, auto patching, advanced monitoring.
	Routine maintenance, backtrack
		
		
	local write forwarding 
		issues write operations from read db instance with same db cluster
		
	add aws region --> global db feature allows you to add db to other regions -> need compatible instance (size etc matters) 
	
	cluster has options for links to db
	
	
	-----Aurora Replicas - Auto Scaling:-----
	
		Client -> writer endpoint and reader endpoint.
			replicas auto scaling --> if reader endpoint a lot of cpu usage then auto scaling.
			
		can make custom endpoint ---> example they are faster so better to run analytical queries.
		
	--Aurora Serverless--
		Automated db instantiation and auto scaling based on usage.
		good for infrequent, intermittent or unpredictable workloads.
		no capacity planning needed.
		pay per second, --> can be more cost effective
		
	--Globl Aurora--
		Aurora Cross Region Read Replicas:
			useful for disaster recovery.
			simple to put in place.
			
		Aurorra Global Db (recommended)
			1 primary region (read/write)
			
			***up to 5 secondary read only regions, lag less than 1 sec.
				Up to 16 Read Replicas per secondary region.
			
			Helps for decreasing latency.
			Promoting another region (for disaster recovery) RTO of <1 min.
			
			Typical cross-region replication takes less than 1 sec.
	
	--Aurora Machine Learning--
		Enables ML based predictions to ur app via SQL.
		Simple, optimized and secure integ b/w aws ML services.
		
			Amazon SageMaker (use with any ml model)
			Amazon Comprehend (for sentiment analysis)
			
		No ML exp req
		Use casse: fraud detection, ads targeting, sentiment analysis, product recommendations.
		
		
	----RDS Backups----
		Automated backups:
			daily full backup.
			transaction logs are backed up by RDS every 5min
			ability to restore to any point in time. (from oldest backup to up to 5min ago)
			1 to 35 days of retention, set 0 to disable.
			
		Manual DB snapshots.
			manually triggered. Retention of backup as long as you want.
			
		Trick: in a stopped RDS db, you will pay for storage. Plan on stopping for long time 
		---> do snapshot and restore it later.
		
	Aurora Backups:
		1 to 35 days (not disabled)
		point in time recovery in timeframe.
		
	Manual DB snapshots.
		Manually triggered by user.
		Retention as long as u want.
		
	--RDS and aurora restore options--
		Restoring RDS/aurrora backup or snapshot creates a new db.
		
		Restoring MySQL RDS db from S3:
			create baclup of ur in premises db.
			store in S3restore bakcup file onto new rds instance running mysql.
			
			**JUST BACKUP OF DP
			
		Restoring MySQL Aurora cluster from s3.
			**using percona xtrabackup
			*then S3 then to  aurora cluster.
			
		Aurora DB Cloning.
			Restoring new DB Cluster from an existing one.
			Faster than snapshot and restore.
			**copy on write protocl.
				initially new db cluster uses same data as orginal cluster ( fast/efficient no copying needed)
				
				When updates made. new db cluster data, additional storage allocated and data is copied to be seperated.
			
		Very fast and cost effective.
		***Useful to create a "staging" db from "production" db without impacting the prod db.
		
		
	-----RDS and aurora security----	
		
		At-rest encryption:
			db master and replicas encryption using AWS KMS - MUST BE defined at launch time.
			if master not encrypted, read replicas cant be rencrypted.
			create snapshot and restore as encrypted for un encrypted db.
			
		In flight encryption: TLS ready by default use AWS TLS root cert client-side.
		IAM Auth: IAM roles to connect to your db (instead of username/pw)
		Security Groups
		No SSH Available except on RDS custom.
		Audit logs can be enabled and sent to cloudwathc logs for retention
		
		
	--Amazon RDS Proxy--
		Fully managed db proxy for RDS.
		
		Allow apps to pool and share db connections established to db.
		***improve db efficiency by reducing stress on db resources (CPU and RAM) and minimize open connections
		serverless,autoscaling, highly available (multi-AZ)
		***Reduced RDS & Aurora Failover time by up to 66%.
		supports MySQL postgress mariadb ms sql and aurora 
		no codes changes req for most apps.
		Enforce IAM Auth for DB and securely store credentials in AWS Secrets Manager.
		Never publically accessible. (only from VPC)
		
	Lambda Functions:
		can multiply many times. can open connections to RDS so have open connections etc 
		so can pool using RDS proxy and overload proxy not db
		
	--ElastiCache--
		Same way RDS is to get managed relational DB.
		Elasticache is to get managed redis or memcached.
		Caches are in memory db with really high performance, low latency.
		***helps reduce load off of db for read intensive workloads
		helps make app stateless.
		aws takes care of OS maint / pathcing, optimzations, setup, config, monitoring failure recovery and backups
		***REQUIRES HEAVY APP CODE CHANGES.
	
			--ElastiCache Solution Architecture - DB Cache--
		
		Applications queries ElastiCache, if not available, get from RDS and store in Elasticache
		---> cache hit
		---> cache miss ---> read from db --> write to cache
		LAZY LOADING
		
		helps relievve load in RDS
		Cache must have an invalidation strategy to make sure only the most current data is used
		
	--ElastiCache Solutional Architecture User Session--
	
		User logs into any of the applications.
		App writes session data into ElastiCache.
		User hits another instance of our app.
		Instance retrieves the data and the user is already logged in --> stateless


	--Redis v.s Memcached--
	
		Redis:	
			Multi AZ with auto failover.
			Read Replicas to scale reads and have high availability.
			Data Duravility using AOF persistence.
			Back and restore featurues
			Support sets and sorted sets.
			
				Replication
			
		Memcached:	for able to lose data etc
			Multi-node for partitioning of data. (sharding)
			No high availability (replication)
			Non persistent
			No backup and restore.
			Mutli threaded architecture
	
				Sharding
 	
 		
		cluster mode for multiple shards in multiple servers.
 		
 		
	--Cache Security--
		ElastiCache supports IAM Auth for Redis.
		IAM policies on ElastiCache are only used for AWS API-level security.
 		
		Redis AUTH:
			You can set a password/token when u create a cluster.
			Extra level of secutiy and support SSL in flight encryption.
			
		MemCached:
			Supports Sasl-based auth
			
	--Patterns--
		
		Lazy Loading: all the read data is cached, data can become stale in achce.
		
		Write Through: Adds or update data in cache when written to a DB
						(no stale data)
		
		Session Store: store temp session data in a cache (using TTL features)
		
		Redis Use Case:
			Gaming Leaderboards --> computationally complex.
			***Redis Sorted sets guarantee both uniqueness and elemnt ordering.
			Each time a new element added, its ranked in real time and added in correct order.
			
			
	Important ports:

		FTP: 21
		SSH: 22
		SFTP: 22 (same as SSH)
		HTTP: 80
		HTTPS: 443

	vs RDS Databases ports:

		PostgreSQL: 5432
		MySQL: 3306
		Oracle RDS: 1521
		MSSQL Server: 1433
		MariaDB: 3306 (same as MySQL)
		Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)
 		
 		
	Multi AZ --> same connection string in RDS, read replicas have diff	
	Aurora Global DB allows multi region aurora dbs with 5 secondary
	
=======Route 53========

	---DNS---
		translates human friendly hostnames into the machine IP addresses.
		DNS backbone of the internet, uses hierarchical naming structure.
		
		--DNS terminologies--
		Domain Registrar: Amazon Route 53, GoDaddy...
		DNS Records: A,AAA,CNAME,NS,...
		Zone file: contains DNS records.
		Name Servers: Resolves DNS Queries (Authoritative or non)
		TLD (top level domain): .com, .us. in
		SLD (second level domain) amazon.com,google.com
		sub domain === www.
		FQDN == fully qualified domain name. api.google.com
		http: protocol
		
	How DNS Works
		
		web browser wants to access example.com
		Local DNS Server --> assigned by ISp dynamically or company.
			If not thr --> Root DNS Server example.com? managed by ICANN
			But ik .com NS 1.2.3.4 so go thr
			--> TLD DNS SERVER for (.com) Managed by IANA (branch of ICANN)
				I know a server that is example.com gives public id.
				--> SLD DNS Server (domain registrar) ---> do you know about example.com? yes I do
		<--- IP sent back
		
		
	---Route 53---
	
	Highly available,scalable, fully managed and authorative DNS.
		Authorative DNS = customer can update DNS records.
		
		Route 53 is also a Domain Registrar
		Ability to check health of your resources.
		***Only AWS service with provides 100% Availability.
		53 = reference to traditional DNS port
		
		---Records---
			How you want to route traffic for a domain.
			
			Each records contains:
				Domain/subdomain name e.g example.com
				
				Record Type e.g A or AAAA
				
				Value e.g 12.34.56.78 route to real ec2 for eg
				
				Routing policy - route 53 responds to queries
				
				TTL - amount of time the record cached at DNS Resolvers.
				
			Route 53 supports DNS record types:
				A/AAAA/CNAME/NS
				
		---Record Types---
		
			A - maps hostname to IPv4
			
			AAAA- maps hostname to IPv6
			
			CNAME - maps hostname to another hostname 
					target can be A or AAAA record
					cant create CNAME record for top node of DNS namespace (zone apex)
					
			NS - Name Servers for the Hosted Zone.
					control how the traffic is routed to domain.
					
		---Hosted Zones---
			container for records that define how to route traffic to a domain.
			
			Public Hosted Zones: contains records specifying how to route traffic to internet
			
			Private Hosted Zones: within one or more VPC (private domain names)
			
			You pay 0.5$ per month per hosted zone.
		
		Records:
			e.g test.example.com  eg NS --> A value --> route test to an ec2 with value. So it can go thr
			if on cloudshell -> install dig and nslookup via sudo yum
				warna works khud
		
		Records TTL(Time to line):
			Dont want to query DNS too often. since they dont change alot.
			High TTL. 24 hours:
				less traffic on Route53.
				outdated records possible.
			Low TTL. e.g 60 secs: opposite.
				easy to change records
			
			Except for Alias --> req for all records
			
		CNAME v.s Alias
			A record = CNAME. hostname to another hostname.
			ONLY FOR NON ROOT DOMAINs.
			
		Alias:
			specific to route54, 
			WORKS FOR BOTH ROOT AND NON ROOT DOMAINS (mydomain.com
			free, native health check
			
			Extension to DNS functionality.
			Automatically recognize changes in IP. no TTL(ig)
			A or AAAA for IPv4 v6
			
			ELB CloudFront Distributions API Gateway. Beanstalk env. S3 Websites. VPC. GLobal Acc. Route 53record.
			
			***NOT FOR EC2 DNS name cant be a target.
			
			myapp.stephanetheteacher.com used and value is alb path. Makes it access the alb	in CNAME.
			
			Alias: route traffic to ALB. region and alb selected. health. myalias.stephanetheteacher.com. Free.
			
		--Routing Policies: route 53:--
			Route 53 responds to DNS queries.
			Routing:
				not same as load balancer routing.
				DNS doesnt route any traffic, only responds to DNS queries.
				
			--Simple--
				Typically route traffic to a single resource.
				randomly chosen by client if multiple values given.
				Alias enabled, then specify AWS resource.
				doesnt allow health checks.
				
			--Weighted--
				% requests go to each specific resources.
				weights given to each record.
				DNS records should have same name and type.
				Load balancing between regions, testing new app version.
				assign weight 0 = no traffic on resource.
				
			--Latency--
				lowest latency.
				measured by user and AWS region connection.
				have to specify region ourselves.
				
			--Failover--
				failover to secondary- disaster recover.
				
			--GEolocation--
				diff from latency based.
				routing based on user location.
				create default record in case no match on location.
				restrict content distribution, web localization, load balacning etc.
				
			--Geoproximity--
				geographic location.
				shift based on bias.
				more bias -> more traffic to resources.
					AWS -> region otherwise lat and long mentioned
					
			--IP based--
				optimize performance, reduce network costs.
				know specific ISP provider then use it.
				
			--Multi Value--
				route to multiple resources.
				associate with health checks.
				up to 8 healthy records can be send for each query.
				Not a subsitute for ELB.
				know it is healthy when returned.
				
				
		--Health Checks--
			e.g Multi region setup ALB. auto scaling.
			
			only passes if 2xx or 3xx status codes. 
			based on text then check first 5120 byes.
			If one region down, go to other region with health check.
		
			 - health checks monitor endpoints.
				-> about 15 global Healthchecks that check. over 80% healthy - healthy
			 
				other health checks ( calculated hc)
					combined multiple hcs. OR AND or NOT. upto 256 childs hc
				monitor cloudwatch alarms. Throttles of DynamoDB, alarms on RDS etc
			integrated with CW metrics.
			-private hz-
				***route 53 health checkers outside VPC. cant access.
				create a CW metric and associate CW alarm, create HC that checks the alarm itself
				
			Domain Registrar v.s DNS Service.
			
				amazon registrar, godaddy etc.
				Domain registrar gives a DNS record via DNS service.
				
				can use another DNS service to manage your DNS records.
				
				all registrars come with some DNS features
	
=======Classic Solution Architecture Discussions========			
			
	Stateful Web App: MyClothes.
		shopcart with user info and shop cart info shouldnt be lost.
		
		- Stickiness -> session affinity. ELB stickiness.
		Same instance always.
		
		- User can store cookies and send shopping cart content in web cookies. can be in diff instances.
			HTTP requests are heavier.
			Cookies can be altered.
			Cookies must be less than 4KB
		
		- Server sessions.
			Session id into elasticache or DynamoDB.
			add cart content into elasticache.
				other ec2 instance. elasticache is looked up from session id.
			
		- Store user data.
			Amazon RDS.
		
		Most usage = reads.
			RDS master. RDS read replicas.
		Read from cache. = lazy loading.
			if not in cache then store in cache and allow hit.
		
		Multi AZ- Survive Disasters.
		open HTTP/HTTPS traffic. in public ip. rest is restricted traffic.
		
	-MyWordPress.com-
		Use aurora mysql (not necessary but still)
		store images -> EBS volume. AZ and EC2 instance issues
				use EFS --> ENI which connect to Ec2 and az.
				
		Aurora DB --> ez Multi AZ and Read Replicas.
		storing EBS good for single. EFS in distribute app
		
	---Instantiating applications quickly---
		EC2 Instances:
			use a golden AMI: install apps OS dependencies, etc beforehand and launch EC2 from golden AMI>
			Bootstrap user data: configure dynamic config, use user data scripts. FOR DYNAMIC ELSE YOU ARE REPEATING THINGS.
			ELASTIC BEAN STALK.
		
		RDS Database:
			Restore a snapshot: db schemas and data ready.
		EBS volumes:
			Restore from a snapshot: disk alrdy formatted nad have data.
			
	
	---BEANSTALK---
		mostly same architecture for web apps.
		-> dev centric view for deploying an app on AWS.
		Uses all components, managed service.
			Auto handle capacity providisioning, load baalncingm sclaing, app, health etc.
			JUST APP CODE DEVS responsibiility.
			Beanstalk is free.
		
		--Components--
			Application: env versions, config etc.
			Application version: an iteration of your app code.
			Environment:
				Collection of AWS resources running an app version.
				Tiers: Web Server Env Tier and Worker Env Tier.
				Create multiple environments.
				
		***Web Server Tier v.s Worker Tier***
		 
			--Web Server--
				traditional architecture -> ELB -> auto scaling ec2 instance.
			
			--Worker--
				pull messages from sqs queue. The more messages = more sqs message instances.
				NO CLIENT SQS QUEUE USED.
				
		
		-- single instance for dev.
		
		-- High availability load balancer great for prod.
		
		stateless tier = dont use EBS bcus it attaches toa ec2 instance.
		use something with session id to access a db like ElastiCache etc
		
		****You want to install software updates on 100s of Linux EC2 instances that you manage. You want to store these updates on shared storage which should be dynamically loaded on the EC2 instances and shouldn't require heavy operations. What do you suggest?
		
		Storing software updates on EFS and mounting it as a network drive at startup is effective because EFS allows multiple EC2 instances to access the same file system simultaneously, simplifying the management of software updates across hundreds of instances without heavy operational overhead. This approach ensures that each instance can easily retrieve the necessary updates on demand, aligning well with efficient, scalable cloud operations.

Was this content relevant to you?


====S3====
	one of the main building blocks in AWS.
	Infinitely scaling storage
		backup
		disaster recovery.
		archive
		app and media hosting.
		data lakes and big data analytics.
		software delivery.
		static website.
		
	--Buckets--
		store objects(files) in "buckets"(directories)
		Buckets must be globally unique accross all regions all accounts.
		buckets are defined in region level.
		S3 Sounds global but is created in regions.
		No uppercase, no underscore.
		3-63 characters long.
		not an IP.
		start with lowercase letter and number	-s3alias cant bhi suffix or xn-- prefix not allowed
		
	--Objects--
		objects(files) have a key.
		Key is the FULL path:
			s3://my-bucket/my_folder/my_file.txt 
			key is composed of prefix + object name.
			prefix = my_folder + w.e then key = my_file.txt
			
		Max obj size is 5TB(5000GB)
		If more than 5GB than use multi part upload.
		
		Metadata (list of key and value pairs)
		Tags. unicode key/value pair. for security/ lifecycle.
		Version ID
		
	pre-signed URL. has credentials encoded.
	
	-- S3 -- Security:
		User-Based:
			which api by which user from IAM.
		Resource-Based:
			Bucket Policies: bucket wide ruels from s3 console.
			Object Access Control List (ACL) finer grain. (can be disabled)
			Bucket Access Control List (ACL) less common.
			
		an IAM principal can access an S3 Object if:
			user iam and resource policy allows  and no explicit DENY.
			
		Encryption:
		
	S3 Bucket Policies:
		json based.
			Resource: buckets and objects.
			effect: allow/deny.
			action: set api.
			principal: acc or user.
		
		can be used to grant public access to bucket.
		force object to encrypt.
		grant access to anoyther account.
		
	IAM policy. use IAM roles
	
	Block settings: 
		block public access.	Prevent company data leaks.
		
	---S3 Static Website hosting---
		host s3 static web.
			URL depends on region.
			need public reads.
	
	---S3 Versioning---
		version files.
		enabled at bucket level.
		same key overwrites will change v.
		protect against unintended deletes.
		easy roll back to prev version.
		Note:
			Any file not versioned prior will be null.
			suspending doesnt del prev versions.
			
		**DELETE MARKER == deleted for that version. delete it to get prev version
		
	---S3 Replication---
		enable versioning in source and desitination buckets
		CRR
			cross region replication
		SRR
			Same region replic
		
		Buckets can be in diff aws acc.
		copying is asyncronous.
		give proper IAM permissions.
		
		CRR --> compliance, lower latency, replication.
		SRR --> log aggregation, live replication between prod and test accounts.
		
		***Only new objects replicated once enabled.
		replicate existiing using S3 Batch Replication.
		
		For DELETE operations.
			can replicate delete markers.
			deletions with a version ID are not replicated
		
		There is no "chaining" of replication.
			if bucket 1 has replication into bucket 2, which has rep into 3.
			then object created in bucket 1 are not replicated to bucket 3.
			
		delete marker replication:
			Replicates delete marker --> delete marker on replicates as well.
		***PERMANENT DELETE DOESNT DELETE ON REPLICATED
		
		Durability:
			High Durability (99%.9999) of objects across multi AZ.
			10,000,000 obj lose 1 in 10,000 years.
			Same for all storage classes.
			
		Availability:
			Measures how readily available a service is.
			99.99% = 53 minutesn ot avaialble per year.
			
	---S3 Storage Classes---
		S3 Standard- General Purpose
			freq access.
			low latency and high throughput.
			
			** Big Data analytics, mobile and gaming apps, content distribution
		
		S3 Standard- Infrequent Access
			less freq acc, rapid access when needed.
			Lower cost than S3.
				99.9% availability
			***Disaster Recovery,backups
		
		S3 One Zone-Infrequent Access
			High durability(99.9%): data lost when AZ destroyed
			99.5% availability
			
			**Storing secondary backup copies of on premise data, data that is replicable.
		
		S3 Glacier Instant Retrieval
			low-cost boject meant for backup/archiving.
			pricing: price for storage + obj retrieval cost.
			**min storage 90 days.
			
		S3 Glacier flexible retrieval
			Epedited(1 to 5min), standard (3 to 5 hours), Bulk(5to 12hours) free.
			**Minimum storage for 90 days
		
		S3 Galcier Deep Archive
			Standard(12 hrs) Bulk(48hours)
			**minimum storage is 180 days
		
		*S3 Intelligent Tiering
			Move obj in between access tiers based on usage.
			small monthly monitoring and auto tiering fee.
			no retrieval charges in s3 IT.
			
			freq access: default.
			Infreq access: obj not access for 30days.
			archive instant access tier: obj 
			archive access(optiona;) from 90 days to 700+ days comfig
			Deep archive access tier (180days to 700+ days)
			
		***EACH FILE AND FOLDER CAN HAVE DIFF TYPE
		
		**can move b/w classes or use s3 lifecycle
		**explicit DENY in an IAM policy overrides any permission granted by an S3 bucket policy,
		
===Advanced S3===














		
	------AWS Integration and messaging-------

		When we start to deploy multiple applications they need to communicate.
		Two patterns 
			- Synchronous communication (app to app) direct connect
					buying service --> shipping service
			- Asynchronous communication: (app to queue to app)
					
		Synchronous b/w app --> one app can overwhelm the other.
		E.g 1000 videos encoded but usually 10 --> video service = overburdened.
			DECOUPLE:
				SQS: queu model
				SNS: pub/sub model
				Kinessi: real time streaming model
		
		-----SQS-----
			Simple Queueing Service.
			
			Producer --> send messages into sqs queue. (e.g process order) (can multiple)
			
			SQS Queue
			
			Consumer ---> Poll messages and process and delete from queue (can be multiple)
			
			-oldest offering (10 yrs+ old)
			-fully managed service, USED TO DECOUPLE APPLICATIONS.
			
			Attributes:
				- Unlimited Throughput, unlimited number of messages in queue.
				- Default retention of messages: 4 days, maximum 14 days.
				- low latency (<10 ms on publish and receive)
				- limitation of 256KB per message sent.
				
			- Can have duplicate messages (atleast once delivery, occassionally)
			- Can have out of order messages (best effort ordering)
			
		---SQS Producing messages---
			messages -> up to 256 kb. --> send to sqs.
			Produced to SQS using SDK (SendMessage API)
			message is persisted in SQS until a consumer deletes it.
			message retention: default 4 days upto 14 days
			
			Example: send order to process:
				orderid, customerid, attributes.
			SQS standard: unlimited Throughput
		
		---SQS Consuming Messages---
			- Consumers (run on EC2, own servers, aws lambda)
			- Poll SQS for messages (receive up to 10 messages at a time)
			- Process the messages (e.g insert messages into an RDS db)
			- Delete messages from queue using DeleteMessage API
			
			
			consumer receive and process messages in parallel. by poll function
			at least once delivery.
			best effort message ordering.
			consumer delete messages after processing them.
			Scale consumers horizontally to improve throughput processing.
			
		---SQS with ASG---
			running in ASG ec2 instance. poll for messages in sqs queue.
			
			Cloudwatch metric --> queue length --> cloudwatch alarm --> increase asg scale
	
		--SQS to decouple between application tiers--
			request and actual processing of file can be in diff sys --> decouplke e.gateway
			eg in backend processing and front end diff. scale seperately. robust and scalable
			
		SQS security:
			Encryption: 
				using https api.
				at rest encryption using kms.
				client side encrtipn
			
			- Access Controls: IAM policies.
			
			- SQS Access Policies (similar to s3 bucket policies)
				useful for cross acc access to SQS queues.
				useful for allowing other services (SNS,S3..) to write an SQS queue.
				
				
		---SQS Message Visibility Timeout---
			After a message is polled by a consumer, it becomes invisible to toher consumers.
			By default the "message visibility timeout" is 30 seconds.
			30 sec to process aka.
			message visible in SQS after timeout
			
			
			........
				
				
				
				
			




		--SQS FIFO Queue--
			- Limited throughput: 300 msg/s without batching, 3000 msg/s with 
			- Exactly once send capability.
			- Messages are processed in order by consumption.
			
		



			
				
				
				
				
===========SERVERLESS============

		Serverless = anything remotely managed, db messages storages etc.
			As long as you dont manage it.
		
		AWS Lambda
		DynamoDb	Trigger lambdafunction
		AWS Cognito
		API Gateway
		S3
		SNS SQS
		Kinesis data
		auroroa serverless
		step function
		fargate
		
	------LAMBDA-----
	
		- virtual functions - no servers.
		- limited by time - short executions.
		- run on demand.
		- scaling is automated.
		
		Easy pricing: pay per request and compute time.
					  free tier of 1,000,000 aws lambda and 400k gbs
					  
		integrated with aws services loads.
		integrated with many languages.
		easy monitoring through aws cloudwatch.
		easy to get more resources per functions (up to 10 gb of ram)
		increase RAM increases CPU and network speed.
		
		custom runtime API (rust and golang)
		Lambda Container Image.
			ECS / Fargate to run instead docker images.
			container image must implement lambda runtime api.
			
		API Gateway:
			Rest API created
		
		Kinesis: 
			data trANSFORMATION
		EventBridge:
			react to things on aws
		DynamoDb:	
			Trigger lambdafunction on db
		SQS:
			process messages from sqs queues
			
		example --> thumbail creation serverless
			new thumbnail in s3 and metadata in dynamoDb
			
			Serverless Cron Job:
				generate job every 5min or monday etc.
				create a cloudwatch event bridge rule that triggers every one hour.
				serverless --> cloudwatch and lambda.
				
		cheap.
		
	---Lambda limits----
		Execution:
			memory allocation: 128MB - 10GB (1MB increments)
			- Max execution time: 900 sec (15min)
			- Env var (4KB)
			- Disk Capacity 512MB to 10GB (/tmp)
			- concurrency executions: 1000
			
		Deployment:
			- lambda function deployment size: 50mb (compressed.zip)
			- size of uncompressed (code + dependencies): 250MB
			- can use /tmp directory to load other fiels at startup
			- size of env: 4 KB
			
	----Lambda SnapStart----
		- JAVA performance up to 10x better at no extra cost. (atleast java 11 or above)
		- enabled - pre initilized state used. initial phase is gone.
			Takse snapshot of memeory and disk state of initialized function.
			snapshot is cached for low latency access.
		
		
	
	AWS Cloud9  ---> Code Editor
	
	AWS Amplify CLI.
	
		AWS Amplify is everything you need to build web and mobile apps. Easy to start, easy to scale.
		It creates a top level directory called amplify that stores your backend definition. 
		It creates a file called aws-exports.js in the src directory that holds all the configuration for the services you create with Amplify. 
		
		amplify add hosting
		rerun app using (manual)
			amplify publish
	
	SAM
		Serverless App Model -> ez to deploy serverless infra 
		AWS SAM defines a set of resources that describe common components of serverless applications.
		
		sam build
		sam deploy --guided


	--Monitoring--
		most imp for lambda functions:
			Errors:
			Execution Time:
			Throttling
		
		In AWS Lambda, the default logging service is Amazon CloudWatch.
			each instance of lambda function has a dedicated log stream.
		
		
	
	Lambda authorizer
		A Lambda authorizer is an API Gateway feature that uses a Lambda function to control
		access to your API. It is a way to add additional security to your API.
	
	-------- SERVERLESS ------------
	
	Software Release Process
		CI / CD		Continous Integration / Continous Deployment
		
		Source > Build > Test > Production
		
		Frameworks > AWS Native
			AWS Native: AWS SAM AWS SDK AWS AMPLIFY
			3rd party: Terraform serverless
			
	AWS SAM
		Transform templates:
			IaC for serverless applications
		AWS CLI
			local dev, build,package and deploy serverless app.
			
			Create ur app 
				init 
				build 
				local 
				logs 
				traces 
				sync
				
			Stack management
				validate 
				package
				delete 
				deploy
				pipeline
				publish
			
			
	AWS CloudFOrmation
	
	AWS SAM. 4 parts:
		Tells cloudformation this is a SAM template it needs to transform.
		Function config
		Permissions for functions
		API Gateway
		
	AWS SAM Pipeline.
		generates resources and config req to build cicd pipeline.
		supports:
			Github Actions
			Jenkins CI
			GitLab
			AWS CodeSuite
			
	AWS SAM Summary
		Define applications with fewer lines of code than cloudofrmation using serverless resource types.
		Supports All AWS CloudFormation Resources.
		Local testing by emulating Lambda and API Gateway
		Accelerate testing on cloud with same accelerate.
		Generate resources and ci cd pipeline.
		
	AWS CDK
		sdk for modeling cloud infrastructure as reusable components
			Abstraction
			Familiar
			Tool Support
			
			
	AWS Amplify
		accelerated and simplifies dev exp for full stack devs
		rich features to quickly create frontends.
		Generates cloudformation for backend
		CI/CD pipeline
		
		For mobile apps usually.
		
	With Lambda function you cant chain functions because they are meant to be stateless . T
	here is another service called AWS StepFunction which you can use to create the orchestration and chain multiple lambda functions and other services. 
	
	There is another way to send message to other lambda function called Lambda Destinations
	- however, AWS StepFunctions is still preferred because it covers a lot more services than just lambda, and have native integration with the services. 
	
	best practices depends - if you are building an event driven architecture, you can either push a success message
	(with context) to a queue or kafka stream may be - and let the listener on the other end take care of the
	message. This way they will be loosely coupled. Aws step function for tight coupling if uk what to do
	
	
	eventBridge:
		created event
		
		
		----rules----
		adding rule
			{
			  "source": ["com.aws.orders"]
			}
		catch all events from com.aws.orders
		
			{
			  "source": ["aws.ec2"],
			  "detail-type": ["EC2 Instance State-change Notification"],
			  "detail": {
				"state": ["terminated"]
			  }
			}
		 process all instance-termination events on ec2
		 
		 the event must contain all the field names listed in the pattern
		
		send events.


	---API destination---
		API destinations are third-party partner targets that you can invoke using an HTTP endpoint. 
		This lets you seamlessly integrate your applications with a range of SaaS partners without having to write code 
		or deploy additional infrastructure. With API destinations, you can easily build modern SaaS-connected solutions, 
		and reduce data silos by simplifying information exchange between applications.
		
	step functions

	SnS challenge
		{
		  "source": ["com.aws.orders"],
		  "detail": {
			"category": ["lab-supplies"],
			"location": [{
			  "prefix": "us-"
			}]
		  }
		}
	---EventBridge Scheduler---
		You can create rules that self-trigger on an automated schedule in EventBridge Scheduler using cron or rate expressions.
		You can specify the time zone, and the minimum precision for schedules is 1 minute.
		
		
	--Schema Registry--
		 Schema Discovery will also detect changes to event schema and automatically generate new schema versions.
		 
		 
		 Schema discovery automates the process of finding schemas and adding them to your registry. 
		 
		 
============================================================================================	
	BUILDING EVENT DRIVEN ARCHITECTURES
	
	--Amazon EventBridge--
		is a serverless event bus service that makes it easy to connect your applications with data from a variety of sources
	
	Events - An event indicates a change in an environment. This can be an AWS environment, an SaaS partner service or application, or one of your own custom applications or services.

	Rules - A rule matches incoming events and routes them to targets for processing. A single rule can route to multiple targets, all of which are processed in parallel.

	Targets - A target processes events. Targets can include Amazon EC2 instances, Lambda functions, Kinesis streams, Amazon ECS tasks, Step Functions state machines, Amazon SNS topics, Amazon SQS queues, and built-in targets. A target receives events in JSON format.

	Event buses - An event bus receives events. When you create a rule, you associate it with a specific event bus, and the rule is matched only to events received by that event bus. Your account has one default event bus, which receives events from AWS services.
	
	
	
	
============================================================================================
	Config management tools
	
	Static 
		Config file on s3 or code repo.
			App can download config on start from S3
			Works for non confidential data.
		AWS Systems Manager Parameter Store
			Hierarchical storage, sensitive data
			Supports data validation
			No complex data types
		AWS Secrets Manager
			secrets with rotation
		
	Dynamic
		AWS App Config.
			flags
			Source Control.
			
	Best practices.
		Automate config changes through pipeline.
		Use default config values in code
		Consider caching dynamic config info
		Avoid configuration bloat
			Periodically review and clean up old configuration.
	
	
	Make sure everything works.
	
		AWS Lambda functions -> 15min or less
								No code issues -> 3rd party ensure if it works
			3rd party services. 	can test with 3rd party
			Manual QA
			Safe deployments
			
	Deployment Strategies.
		All at once
			All changes at the same time.
			If any issues --> rollback
			Risk of downtime.
			Fastest way of deployment.
			Better for low concurrency workloads and dev/staging env
			
		Blue/Green
			Deploy to a new stack/switch traffic to new stack.
			Observing near stack go back to old stack if error.
			Reduces downtime.
			Medium Concurrency.
			
		Canary
			Deploy changes to a new stack.
			Send like 10-30% of traffic to new stack.
			Observe Increase traffic slowly. Downtime impacts only fraction of users.
			Better for high concurrency workloads.
			
	Lambda Versions and aliases.
		Versions immutable snapshots of a function code + config
		Alias pointer to a version	Can change alias to another version once confirmed.
		
	DNS with route53.
		Diff traffic directed to diff places according to diff geographical regions.
		Blue/Green and Canary
		
	Diff strats for dif fstages.
		Dev		Stage		Prod
		AllatOnce 		Canary at Linear10%Every1Min
	
	use canary releases to get tech and business feedback.
	
	SECURITY IN SERVERLESS:
		 shifts security Responsibility towards AWS 
		 and Left security shifts to Organization.
		
	Security is a shared responsibility ---> customer + AWS
	Serverless ---> Shigts a lot more to aws customer only IAM customer functions and resource fdonifg
	AWS compute scaling up and down network infra regions etc.
	
	Controll access to services with IAM
		- Control plane actions -> manage resources like createFunciton updateStateMachine.
		
		- Data plane actions execute on dialy business 
			Invoke 
			PutEvents
		
	Lambda Function Isolation
		Function runs in dedicated sandbox
	sandbox reuse:
		may be reused b/w invocations = improve latency and reuse prev initialized connections.
	
		Use caution when storing sensitive data in memory or /tmp
	
	Traditional approach
		Heavy emphasis on perimeter security and alarms.
		apps deployed within secured perimeter.
		
	Modern approach.
		Implement defense in depth.
		Secure each component of the workload
		Focus on IAM.
		Apply perimiter security if exposed to internet.
		Leverage AWS WAF, API Gateway.
		Managed services provide a strong basis.
	
	Least Privilege
		**Be specific
		Function Policy:
			Who can invoke function 
			
		Execution Policy:
			What can the function do?
	
	
	Defense in Depth:
		Access control and data path protection
	
		SQS encrypted by default.
		ABAC support in SQS.
		SNS data protection -> discover and protect sensitive data in motion
		
	---retrieve secrets in lambda functions---
		AWS Secrets Manager:
			Init once then invocation:
				Uses secrets.
				Across invocation stash db? or not? mostly not understand service.
				
	validate untrusted event payloads.
		Validate input before processing before parsing.
		Use Strict typing
		Consider for all event sources.
	
		API gateway has many options
	
	Use a framework!
		empowers devs to safely create policies.
		
	AWS Config ProActive controls.
		proactive/continously monitor instances.
		
	Code scanning with amazon inspector.
		Scan for vulnerabilities in env
			Standard scans/ code scans.
		Proactively monitor.
		
	Lambda functions always run in VPCS owned by service team.
		Only neded if VPC resource access needed or must meet a security control.
		
	Amazon GuardDuty
	
	---------Serverless Observability-------
	traditional monitoring layers:
		Business and Application + Data	mostly concerned for customers.
		Rest AWS in serverless.
		
	monitoring more than failures:
	is it behaving as expected? usage? business impact?
	
	Observability:
		Metrics Logs Traces(trace user actions)
		
	AWS Observability tools.
		AWS CloudWatch logs. CW Metrics. X ray
	
	CloudWatch
		Collect 
		
		Monitor 
		
		Act 
		
		Analyze
	
	CloudWatch Logs.
		Metric FIlters:
			Metrics based on log filters e.g count of 4xx errors
			Jump to logs that generated metric.
		Lambda Logging.
		API Gateway Rest logging.
		
		Standard Structured Logging.
			json -> Send it to cloudwatch log 
	
=====Amazon API Gateway=====

	API -> abstracts underlying implementation and only exposes objects or actions the dev needs
	
	Fully managed serverless service --> easy for dev to create,publish,maintain and secure APIS at any scale.
	
	RESTful APis.
		Methods Get,Post etc -> req / response format
		Short lived
		
			REST API -> feature rich (v1)
			HTTP API is faster: lower cost: easier to use (v2)
			
	WebSocket APIs
		Long--lived communication
		Serverless 
		
	---Endpoint types---
	
	Edge-Optimized: REST API only (no HTTP)
		utilizes cloudfront to reduces tls connection overhead (closes edge point)
		for globally distributed set of clients
	
	Regional:
		Recommeded API type for general use case.
		Designed for building APIs for client in the same region
	
	Private: 	REST API only
		only accessible from within VPC
		designed for building APIs used internally or by private microservices.
		
	
	Integrations:
		lambda functions
		public http endpoints
		any other aws service.
			Private:
			Endpoint in VPC or aws direct connect
			on premises
			
		VPC link:
			
		Req cycle:
			WAF Authenticate Authorizer Authorize -> integration
			
			WAF ACL configured for enhanced security (who can send req etc)
			
		Client certiticates.
			generate ssl cert useing api gateway
			365 days public
			
		...
		.
		.
		.
		.
		.
		encryption in transit
		
		Throttling and usage plans.
			Protect backend system,
			
			
		...
		.
		.
		.
		.
		.
		
		Caching
			Minimal load to backend.
			setup per stage or method.
			
		
		Best Practices:
			Use HTTP Apis if existing feature sufficient.
			create an API per team/microservice and unify with custom domain name.
			Console is for experimenting. Use infra as code:
				SAM CloudFormation etc.
				
	======Synchronous req-res model========
		
		Low latency simple and fail fast.
		
		Receiver failure, throttled.
		
	----Asynch-----
		Queue
	Advantage
		Decrease coupling.
		resilient to receiver failure
		receiver controls consumption rate.
		Dead Letter Queue for errors.
		
	Disadvantages
		Backlog recovery time
		Fairness in multi tenant systems.
		Response correlation
		
	CAN USE SQS
		fully managed message queue
		scale infinite 
		simple easy to use api
		DLQ and FIFO options
		
		
	message channels
	
		Point to point queue
			Sender -->  Receivers
				SQS
				Cloud native and serverless
		
		Publish Subscribe (topic)
			Publishers ---> Subs
				SNS  cloud native and serverless
				
	Event Bridge
	
		event exmaple rule and example event etc Current match
		
	Event uniqueness 
		Handle it otherwise issues. receiver should have logic to deal with idempotency
		
		
		....
		
		....
	....
	
	...
	...
	AWS Step functions
	
		Task integration Patterns
		
			request-response:
			
			run a job
			
			wait for a callback
			
			
	Activity tasks v.s wait for callback
	
	push v.s pull
	
	