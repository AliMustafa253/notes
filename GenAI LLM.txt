Generative AI use cases, project lifecycle, and model pre-training

Fine-tuning and evaluating large language models

Reinforcement learning and LLM-powered applications


===============================================================
How an LLM works:

	- Transformer architecture why it took off etc.
	
	- Gen AI project life cycle.
		foundation model off the shelf, or make my own model etc.
		


	
----------------------------------------------------------
	Gen AI --> subset of ML
		---> learn patterns in datasets of contents generated by humans.
		---> foundation models, BERT,GPT,LLaMa,FLANT-5, PALM
		
		LLM take human written instructions --> prompt
		Context window ---> like a few 1000 windows.
		
		Completion ---> complete prompts
		
	---------
	
	Chat tasks ---> Next word prediction: Basic Chatbot
	
	translation/natural lang to code/file to summary etc/information retrieval (NER)/
	augmenting llms with integrate with apis.
	
	-----------
	
	RNN --> limited. needs more scaling and needs to see more
			than prev few words
			
	
	ATTENTION IS ALL YOU NEED
	
	
	--------------
	Transformers
	--------------
	learns context of all words. applies weights.
	
	- attention weights applied to each other word in sentences during llm training.
	
	- improved encoding language ability a lot
	
	- ****Self Attention
			strongly connected to or paying attention to something.
	
	- Transformers Architecture 
		----> Encoder and Decoder.
		
		big statistical calculators. must tokenize words into numbers.
		
	****tokenization methods --> token Ids, to represent part of word or whole words.
	
	Embedding space ----> Each token is represented as a vector:
	Vector ---> learn to encode meaning and context of each individual sequence.
	
	eg vector of just 3 --> relate words closer calc diff with angles etc.
	
	positional encoding: ---> preserve word order and position of word in sentence.
	
	****Token embeddings + positional encoding.
	-----------
	***GOES TO SELF ATTENTION LAYER ---> Encoder and Decoder
	
	Multi-headed Self Attention. ---> multiple heads learn indibivdually.
					each self attention head learns diff aspects 12-100 may be possible.
	-----------			
	*****GOES TO FEED FORWARD NETWORK 
		Vector of logics for probability of each token.
		final softmax layer ---> probability for each word in vocabulary.
		one token --> higher prob.
		
		feed-forward network applies a point-wise fully connected layer
		to each position separately and identically. 
	
	================================
	Translation using Transformers:
	Sequence to sequence task
		encoder deep representation of structure and meaning of sentence
		--> decoder	startup input trigger to predict next token.
		Output --> through feedforward layer to softmax output.
		New token and new token put forward.
		
		
	****Encoder:
		Encodes inputs (prompts) with contextual understanding
			produces one vector per input token.
			
	****Decoder:
		accepts input tokens and generates new tokens.
		
	BERT = ENCODER ONLY MODEL.
	
	BART and T5 === Encoder decoder models.
	
	GPT, LLaMa === DECODER ONLY MODELS.
		
		
	------------------------------------
	Context Window = total size allowed for prompt.
	
	**in-context learning
	
		zero shot inference.
		
		one shot inference.
		
		few-shot inference.
		
	***configuration parameters.
		Different than training parameters --> give u control over things etc.
		
		max new tokens === cap on how many times it can go back on the model.
	
		softmax of words and probability. has complete dictionary.
		
		greedy decoding --> pick highest probability --> good for short generation.
		more natural ---> random sampling --> (weighted with probability).
		
	***Sample top K and Top P
		Top K ---> only choose from top K tokens, randomness but more likely to be reasonable.
		Top P ---> predictions combine probability doesnt exceed e.g 0.3
		
		Temperature: higher --> higher randomness
		
	======================================
	GenAI lifecycle:
		
		Scope ---> Select ----> Adapt and align model ----> Application integration
		
		
		Scope:
			Define as accurately and narrowingly.
				What functions:
					Many different tasks?
					single task like NER?
					
		Select:
			Choose model. Generally base model 
		
		Adapt and Align Model:
			Prompt Engineering --> in context learning.
			
			Fine tuning --> supervised learning process.
			
			Align with human feedback (reinforcement learning with human feedback)
			
			Evaluate
		
		Application Integration:
			optimize and deploy model for inference.
			Augment model and build LLM powered applications.
			
		
		
			
		
			
	